{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于**Learning both Weights and Connections for Efficient Neural Network**论文的progan模型修剪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0727 12:37:48.815481 139634556143424 deprecation_wrapper.py:119] From /tf/notebooks/progressive_growing_of_gans-master/tfutil.py:56: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0727 12:37:48.816479 139634556143424 deprecation_wrapper.py:119] From /tf/notebooks/progressive_growing_of_gans-master/tfutil.py:57: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "W0727 12:37:48.832114 139634556143424 deprecation_wrapper.py:119] From /tf/notebooks/progressive_growing_of_gans-master/tfutil.py:65: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0727 12:37:48.832686 139634556143424 deprecation_wrapper.py:119] From /tf/notebooks/progressive_growing_of_gans-master/tfutil.py:72: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0727 12:37:49.744889 139634556143424 deprecation_wrapper.py:119] From /tf/notebooks/progressive_growing_of_gans-master/tfutil.py:477: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks from \"model/pgan-wm3000-20000.pkl\"...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#import dnnlib\n",
    "#import dnnlib.tflib as tflib\n",
    "import tfutil\n",
    "import dataset\n",
    "import misc\n",
    "import numpy as np\n",
    "import config \n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "\n",
    "path = 'model/'+'pgan-wm3000-20000'\n",
    "tfutil.init_tf(config.tf_config)\n",
    "with tf.device('/gpu:0'):\n",
    "    network_pkl = misc.locate_network_pkl(path+'.pkl')\n",
    "    print('Loading networks from \"%s\"...' % network_pkl)\n",
    "    G, D, Gs = misc.load_pkl(network_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dict1 = Gs.__getstate__()\n",
    "# for item in dict1['variables']:\n",
    "#     print(item[0])\n",
    "# for item in G.vars:\n",
    "#     print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import dnnlib.tflib.tfutil as tfutil\n",
    "import numpy as np\n",
    "def threshold_calculation(w_conv, layer_name,prune_rate):\n",
    "   # w_conv = item[1] # weight四维参数\n",
    "    w_parameter = sorted(abs(w_conv.flatten()))\n",
    "    print(layer_name)\n",
    "#     print('参数裁剪前总和',sum(w_parameter))\n",
    "#     print('参数个数',len(w_parameter))\n",
    "    print('裁剪个数',int(len(w_parameter) * prune_rate))\n",
    "    threshold = w_parameter[int(len(w_parameter) * prune_rate)]\n",
    "    print('阈值',threshold)\n",
    "    return threshold\n",
    "    \n",
    "\n",
    "def prune_main(G, D, Gs,prune_rate):\n",
    "    print('---------',prune_rate,'---------')\n",
    "#     dict_Gs = Gs.__getstate__()\n",
    "    dict_variables = G.vars#dict_Gs['variables']\n",
    "    \n",
    "    for item in dict_variables:\n",
    "#         print(item)\n",
    "        #if (item.find('Conv') == -1 or item.find('up') != -1):\n",
    "        if (item.find('Conv') == -1):\n",
    "            continue    \n",
    "\n",
    "        if '/weight' in item:              \n",
    "            w_conv = Gs.get_var(item) # weight四维参数\n",
    "            threshold = threshold_calculation(w_conv , item, prune_rate)\n",
    "\n",
    "            for item1 in range(len(w_conv)):\n",
    "                for item2 in range(len(w_conv[0])):\n",
    "                    for item3 in range(len(w_conv[0][0])):\n",
    "                        for item4 in range(len(w_conv[0][0][0])):\n",
    "                            if abs(w_conv[item1][item2][item3][item4]) < threshold:\n",
    "                                w_conv[item1][item2][item3][item4] = 0\n",
    "           # w_parameter = sorted(abs(w_conv.flatten()))  \n",
    "            Gs.set_var(item, w_conv)\n",
    "            G.set_var(item, w_conv)\n",
    "#             print('参数裁剪后总和',sum(w_parameter))\n",
    "        if '/mod_weight' in item:              \n",
    "            w_conv = Gs.get_var(item)\n",
    "            threshold = threshold_calculation(w_conv,item, prune_rate)\n",
    "\n",
    "            for item1 in range(len(w_conv)):\n",
    "                for item2 in range(len(w_conv[0])):\n",
    "                    if abs(w_conv[item1][item2]) < threshold:\n",
    "                        w_conv[item1][item2] = 0    \n",
    "#             print('参数裁剪后总和',sum(w_parameter))           \n",
    "\n",
    "            \n",
    "    pkl = os.path.join('model/','test_%d.pkl'%(prune_rate*100))\n",
    "    misc.save_pkl((G, D, Gs), pkl)  \n",
    "    print('--------模型model/','test_%d.pkl'%(prune_rate*100),'保存完毕--------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- 0 ---------\n",
      "4x4/Conv/weight\n",
      "裁剪个数 0\n",
      "阈值 1.3969839e-08\n",
      "8x8/Conv0_up/weight\n",
      "裁剪个数 0\n",
      "阈值 1.4416873e-06\n",
      "8x8/Conv1/weight\n",
      "裁剪个数 0\n",
      "阈值 1.6763806e-08\n",
      "16x16/Conv0_up/weight\n",
      "裁剪个数 0\n",
      "阈值 0.0\n",
      "16x16/Conv1/weight\n",
      "裁剪个数 0\n",
      "阈值 2.2199747e-06\n",
      "32x32/Conv0_up/weight\n",
      "裁剪个数 0\n",
      "阈值 1.1920929e-07\n",
      "32x32/Conv1/weight\n",
      "裁剪个数 0\n",
      "阈值 2.1979213e-07\n",
      "--------模型model/ test_0.pkl 保存完毕--------\n",
      "--------- 0.1 ---------\n",
      "4x4/Conv/weight\n",
      "裁剪个数 235929\n",
      "阈值 0.14334361\n",
      "8x8/Conv0_up/weight\n",
      "裁剪个数 235929\n",
      "阈值 0.14468355\n",
      "8x8/Conv1/weight\n",
      "裁剪个数 235929\n",
      "阈值 0.14387304\n",
      "16x16/Conv0_up/weight\n",
      "裁剪个数 235929\n",
      "阈值 0.14402883\n",
      "16x16/Conv1/weight\n",
      "裁剪个数 235929\n",
      "阈值 0.14296535\n",
      "32x32/Conv0_up/weight\n",
      "裁剪个数 235929\n",
      "阈值 0.14263958\n",
      "32x32/Conv1/weight\n",
      "裁剪个数 235929\n",
      "阈值 0.14081691\n",
      "--------模型model/ test_10.pkl 保存完毕--------\n",
      "--------- 0.9 ---------\n",
      "4x4/Conv/weight\n",
      "裁剪个数 2123366\n",
      "阈值 1.8782599\n",
      "8x8/Conv0_up/weight\n",
      "裁剪个数 2123366\n",
      "阈值 1.8984601\n",
      "8x8/Conv1/weight\n",
      "裁剪个数 2123366\n",
      "阈值 1.8878767\n",
      "16x16/Conv0_up/weight\n",
      "裁剪个数 2123366\n",
      "阈值 1.890611\n",
      "16x16/Conv1/weight\n",
      "裁剪个数 2123366\n",
      "阈值 1.8893297\n",
      "32x32/Conv0_up/weight\n",
      "裁剪个数 2123366\n",
      "阈值 1.8783312\n",
      "32x32/Conv1/weight\n",
      "裁剪个数 2123366\n",
      "阈值 1.8770648\n",
      "--------模型model/ test_90.pkl 保存完毕--------\n"
     ]
    }
   ],
   "source": [
    "# prune_rates = [0.1,0.3,0.5,0.7,0.9] #修剪的概率\n",
    "prune_rates = [0,0.1,0.9]\n",
    "# prune_rates = [0.9]\n",
    "for prune_rate in prune_rates:\n",
    "    prune_main(G, D, Gs,prune_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型评估\n",
    "- is\n",
    "- fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming data using dataset.TFRecordDataset...\n",
      "Dataset shape = [3, 32, 32]\n",
      "Dynamic range = [0, 255]\n",
      "Label size    = 10\n",
      "Initializing metrics.frechet_inception_distance.API...\n",
      "[3, 32, 32]\n",
      "\n",
      "Snapshot  Time_eval   FID       \n",
      "---       ---         ---       \n",
      "Reals     2m 18s      -0.0000   \n",
      "90        2m 34s      104.0909  \n",
      "10        2m 27s      8.1116    \n",
      "0         2m 35s      8.1207    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tfutil\n",
    "import dataset\n",
    "import misc\n",
    "import numpy as np\n",
    "import config \n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "import config\n",
    "import time\n",
    "\n",
    "def evaluate_metrics(snapshot_pkls,dataset_cfg,metrics):\n",
    "    metric_class_names = {\n",
    "        'swd':      'metrics.sliced_wasserstein.API',\n",
    "        'fid':      'metrics.frechet_inception_distance.API',\n",
    "        'is':       'metrics.inception_score.API',\n",
    "        'msssim':   'metrics.ms_ssim.API',\n",
    "    }\n",
    "     \n",
    "    pklpath = 'model'\n",
    "    \n",
    "    num_images=50000\n",
    "    real_passes=1\n",
    "    \n",
    "    # 初始化模型\n",
    "#     network_pkl = misc.locate_network_pkl(pklpath+'.pkl')\n",
    "#     snapshot_pkls = ['model/test_0.pkl','model/test_10.pkl','model/test_20.pkl','model/test_30.pkl',\n",
    "#                      'model/test_40.pkl','model/test_50.pkl','model/test_60.pkl','model/test_70.pkl',\n",
    "#                      'model/test_80.pkl','model/test_90.pkl']\n",
    "    \n",
    "    # 加载数据\n",
    "    dataset_obj = dataset.load_dataset(data_dir=config.data_dir, **dataset_cfg)\n",
    "    mirror_augment = True\n",
    "    minibatch_size = np.clip(8192 // dataset_obj.shape[1], 4, 256)\n",
    "    \n",
    "    # 初始化metrics\n",
    "#     metrics=['is','fid']\n",
    "    metric_objs = []\n",
    "    for name in metrics:\n",
    "        class_name = metric_class_names.get(name, name)\n",
    "        print('Initializing %s...' % class_name)\n",
    "        class_def = tfutil.import_obj(class_name)\n",
    "        image_shape = [3] + dataset_obj.shape[1:]\n",
    "        print(image_shape)\n",
    "        obj = class_def(num_images=num_images, image_shape=image_shape, image_dtype=np.uint8, minibatch_size=minibatch_size)\n",
    "        tfutil.init_uninited_vars()\n",
    "        mode = 'warmup'\n",
    "        obj.begin(mode)\n",
    "        for idx in range(10):\n",
    "            obj.feed(mode, np.random.randint(0, 256, size=[minibatch_size]+image_shape, dtype=np.uint8))\n",
    "        obj.end(mode)\n",
    "        metric_objs.append(obj)\n",
    "\n",
    "    # Print table header.\n",
    "    print()\n",
    "    print('%-10s%-12s' % ('Snapshot', 'Time_eval'), end='')\n",
    "    for obj in metric_objs:\n",
    "        for name, fmt in zip(obj.get_metric_names(), obj.get_metric_formatting()):\n",
    "            print('%-*s' % (len(fmt % 0), name), end='')\n",
    "    print()\n",
    "    print('%-10s%-12s' % ('---', '---'), end='')\n",
    "    for obj in metric_objs:\n",
    "        for fmt in obj.get_metric_formatting():\n",
    "            print('%-*s' % (len(fmt % 0), '---'), end='')\n",
    "    print()\n",
    "\n",
    "    # Feed in reals.\n",
    "    for title, mode in [('Reals', 'reals'), ('Reals2', 'fakes')][:real_passes]:\n",
    "        print('%-10s' % title, end='')\n",
    "        time_begin = time.time()\n",
    "        labels = np.zeros([num_images, dataset_obj.label_size], dtype=np.float32)\n",
    "        [obj.begin(mode) for obj in metric_objs]\n",
    "        ############  \n",
    "        for begin in range(0, num_images, minibatch_size):\n",
    "            end = min(begin + minibatch_size, num_images)\n",
    "            images, labels[begin:end] = dataset_obj.get_minibatch_np(end - begin)\n",
    "            if mirror_augment:\n",
    "                images = misc.apply_mirror_augment(images)\n",
    "            if images.shape[1] == 1:\n",
    "                images = np.tile(images, [1, 3, 1, 1]) # grayscale => RGB\n",
    "            [obj.feed(mode, images) for obj in metric_objs]\n",
    "        results = [obj.end(mode) for obj in metric_objs]\n",
    "        print('%-12s' % misc.format_time(time.time() - time_begin), end='')\n",
    "        for obj, vals in zip(metric_objs, results):\n",
    "            for val, fmt in zip(vals, obj.get_metric_formatting()):\n",
    "                print(fmt % val, end='')\n",
    "        ############        \n",
    "        print()\n",
    "        \n",
    "    # Evaluate each network snapshot.\n",
    "    for snapshot_idx, snapshot_pkl in enumerate(reversed(snapshot_pkls)):\n",
    "        prefix = 'test_'; postfix = '.pkl'\n",
    "        snapshot_name = os.path.basename(snapshot_pkl)\n",
    "        assert snapshot_name.startswith(prefix) and snapshot_name.endswith(postfix)\n",
    "        snapshot_kimg = int(snapshot_name[len(prefix) : -len(postfix)])\n",
    "\n",
    "        print('%-10d' % snapshot_kimg, end='')\n",
    "        mode ='fakes'\n",
    "        [obj.begin(mode) for obj in metric_objs]\n",
    "        time_begin = time.time()\n",
    "        with tf.Graph().as_default(), tfutil.create_session(config.tf_config).as_default():\n",
    "            G, D, Gs = misc.load_pkl(snapshot_pkl)\n",
    "            for begin in range(0, num_images, minibatch_size):\n",
    "                end = min(begin + minibatch_size, num_images)\n",
    "                latents = misc.random_latents(end - begin, Gs)\n",
    "                images = Gs.run(latents, labels[begin:end], num_gpus=1, out_mul=127.5, out_add=127.5, out_dtype=np.uint8)\n",
    "                if images.shape[1] == 1:\n",
    "                    images = np.tile(images, [1, 3, 1, 1]) # grayscale => RGB\n",
    "                [obj.feed(mode, images) for obj in metric_objs]\n",
    "        results = [obj.end(mode) for obj in metric_objs]\n",
    "        print('%-12s' % misc.format_time(time.time() - time_begin), end='')\n",
    "        for obj, vals in zip(metric_objs, results):\n",
    "            for val, fmt in zip(vals, obj.get_metric_formatting()):\n",
    "                print(fmt % val, end='')\n",
    "        print()\n",
    "    print()\n",
    "    \n",
    "snapshot_pkls = ['model/test_0.pkl','model/test_10.pkl','model/test_90.pkl']\n",
    "dataset_cfg = {'tfrecord_dir': 'cifar10_wm3000_mullabel', 'max_label_size': 'full', 'verbose': True, 'shuffle_mb': 0}\n",
    "\n",
    "# metrics=['is']\n",
    "# evaluate_metrics(snapshot_pkls,dataset_cfg,metrics)    \n",
    "# metrics=['fid']\n",
    "# evaluate_metrics(snapshot_pkls,dataset_cfg,metrics) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 批量生成图片 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming data using dataset.TFRecordDataset...\n",
      "Dataset shape = [3, 32, 32]\n",
      "Dynamic range = [0, 255]\n",
      "Label size    = 10\n",
      "dataset load finish\n"
     ]
    }
   ],
   "source": [
    "import train\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "training_set = dataset.load_dataset(data_dir=config.data_dir, **dataset_cfg)\n",
    "print('dataset load finish')\n",
    "\n",
    "def generate_images(pklpath,training_set):\n",
    "    tfutil.init_tf(config.tf_config)\n",
    "    # 载入模型\n",
    "    with tf.device('/gpu:0'):\n",
    "    #     if resume_run_id is not None:\n",
    "            #network_pkl = misc.locate_network_pkl(resume_run_id, resume_snapshot)\n",
    "        network_pkl = misc.locate_network_pkl(pklpath)\n",
    "        print('Loading networks from \"%s\"...' % network_pkl)\n",
    "        G, D, Gs = misc.load_pkl(network_pkl)\n",
    "        grid_size, grid_reals, grid_labels, grid_latents = train.setup_snapshot_image_grid(G, training_set, **config.grid)\n",
    "    # 创建图片文件夹\n",
    "    path = 'model/quality_assessment/'\n",
    "    filename = pklpath.split('/')[-1].split('.')[0]\n",
    "    if os.path.exists(path+filename):\n",
    "        print('%s文件夹重置'%filename)\n",
    "        shutil.rmtree(path+filename)\n",
    "    os.mkdir(path+filename)\n",
    "    \n",
    "    # 生成图片\n",
    "    for i in range(200):\n",
    "        grid_labels[i] = [1, 0, 0, 0, 1, 1, 0, 0, 0, 1]\n",
    "        label = 11\n",
    "        grid_fakes = Gs.run(np.matrix(grid_latents[i]),np.matrix(grid_labels[i]), is_validation=True, randomize_noise=True) \n",
    "        misc.save_image_grid(grid_fakes, os.path.join(path+filename+'/fakes%d.png'%(i)), drange=[-1,1], grid_size=[1,1])\n",
    "    print('%s生成图片成功'%(path+filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks from \"model/test_0.pkl\"...\n",
      "test_0文件夹重置\n",
      "model/quality_assessment/test_0生成图片成功\n",
      "Loading networks from \"model/test_10.pkl\"...\n",
      "test_10文件夹重置\n",
      "model/quality_assessment/test_10生成图片成功\n",
      "Loading networks from \"model/test_90.pkl\"...\n",
      "test_90文件夹重置\n",
      "model/quality_assessment/test_90生成图片成功\n"
     ]
    }
   ],
   "source": [
    "for pklpath in snapshot_pkls:\n",
    "    generate_images(pklpath,training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
